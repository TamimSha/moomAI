{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        #input shape\n",
    "        self.channels = 3\n",
    "        self.lr_height = 136\n",
    "        self.lr_width = 180\n",
    "        self.lr_shape = (self.lr_height, self.lr_width, self.channels)\n",
    "        self.hr_height = self.lr_height * 4\n",
    "        self.hr_width = self.lr_width * 4\n",
    "        self.hr_shape = (self.hr_height, self.hr_width, self.channels)\n",
    "\n",
    "        #number of residual blocks\n",
    "        self.n_residual_blocks = 16\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Vgg for descrimination\n",
    "        self.vgg = self.build_vgg()\n",
    "        self.vgg.trainable = False\n",
    "        self.vgg.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.hr_height / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # High res. and low res. images\n",
    "        img_hr = Input(shape=self.hr_shape)\n",
    "        img_lr = Input(shape=self.lr_shape)\n",
    "\n",
    "        # Generate high res. version from low res.\n",
    "        fake_hr = self.generator(img_lr)\n",
    "\n",
    "        # Extract image features of the generated img\n",
    "        fake_features = self.vgg(fake_hr)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminator determines validity of generated high res. images\n",
    "        validity = self.discriminator(fake_hr)\n",
    "\n",
    "        self.combined = Model([img_lr, img_hr], [validity, fake_features])\n",
    "        self.combined.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    def build_vgg(self):\n",
    "        vgg = VGG19(weights='imagenet')\n",
    "        vgg.outputs = [vgg.layers[9].output]\n",
    "        img = Input(shape=self.hr_shape)\n",
    "        img_features = vgg(img)\n",
    "        return Model(img, img_features)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        def residual_block(layer_input, filters):\n",
    "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
    "            d = Activation('relu')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Add()([d, layer_input])\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input):\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
    "            u = Activation('relu')(u)\n",
    "            return u\n",
    "\n",
    "        # Low resolution image input\n",
    "        img_lr = Input(shape=self.lr_shape)\n",
    "        # Pre-residual block\n",
    "        c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(img_lr)\n",
    "        c1 = Activation('relu')(c1)\n",
    "        # Propogate through residual blocks\n",
    "        r = residual_block(c1, self.gf)\n",
    "        for _ in range(self.n_residual_blocks - 1):\n",
    "            r = residual_block(r, self.gf)\n",
    "        # Post-residual block\n",
    "        c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
    "        c2 = BatchNormalization(momentum=0.8)(c2)\n",
    "        c2 = Add()([c2, c1])\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(c2)\n",
    "        u2 = deconv2d(u1)\n",
    "        # Generate high resolution output\n",
    "        gen_hr = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)\n",
    "        return Model(img_lr, gen_hr)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_block(layer_input, filters, strides=1, bn=True):\n",
    "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        # Input img\n",
    "        d0 = Input(shape=self.hr_shape)\n",
    "        d1 = d_block(d0, self.df, bn=False)\n",
    "        d2 = d_block(d1, self.df, strides=2)\n",
    "        d3 = d_block(d2, self.df*2)\n",
    "        d4 = d_block(d3, self.df*2, strides=2)\n",
    "        d5 = d_block(d4, self.df*4)\n",
    "        d6 = d_block(d5, self.df*4, strides=2)\n",
    "        d7 = d_block(d6, self.df*8)\n",
    "        d8 = d_block(d7, self.df*8, strides=2)\n",
    "        d9 = Dense(self.df*16)(d8)\n",
    "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "        validity = Dense(1, activation='sigmoid')(d10)\n",
    "        return Model(d0, validity)\n",
    "\n",
    "    def train(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset_name, img_res=(136, 180)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "\n",
    "    def load_data(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"test\"\n",
    "        \n",
    "        path = glob('./datasets/%s/*' % (self.dataset_name))\n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "        imgs_hr = []\n",
    "        imgs_lr = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "\n",
    "            h, w = self.img_res\n",
    "            low_h, low_w = int(h / 4), int(w / 4)\n",
    "\n",
    "            img_hr = scipy.misc.imresize(img, self.img_res)\n",
    "            img_lr = scipy.misc.imresize(img, (low_h, low_w))\n",
    "\n",
    "            # If training => do random flip\n",
    "            if not is_testing and np.random.random() < 0.5:\n",
    "                img_hr = np.fliplr(img_hr)\n",
    "                img_lr = np.fliplr(img_lr)\n",
    "\n",
    "            imgs_hr.append(img_hr)\n",
    "            imgs_lr.append(img_lr)\n",
    "\n",
    "        imgs_hr = np.array(imgs_hr) / 127.5 - 1.\n",
    "        imgs_lr = np.array(imgs_lr) / 127.5 - 1.\n",
    "\n",
    "        return imgs_hr, imgs_lr\n",
    "\n",
    "\n",
    "    def imread(self, path):\n",
    "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598867635281",
   "display_name": "Python 3.8.5 64-bit ('tensor': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}