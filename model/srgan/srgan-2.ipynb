{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599482163872",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Add\n",
    "from keras.layers import BatchNormalization, LeakyReLU, PReLU, Conv2D, Dense\n",
    "from keras.layers import UpSampling2D, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.utils.data_utils import OrderedEnqueuer\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LambdaCallback\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "    def __init__(self,\n",
    "        height_lr=56, width_lr=56, channels=3,\n",
    "        upscaling_factor=4,\n",
    "        gen_lr=1e-4, dis_lr=1e-4, loss_weights=[1e-3, 0.006],\n",
    "        training_mode=True):\n",
    "\n",
    "        self.height_lr = height_lr\n",
    "        self.width_lr = width_lr\n",
    "\n",
    "        self.upscaling_factor = upscaling_factor\n",
    "        self.height_hr = int(self.height_lr * self.upscaling_factor)\n",
    "        self.width_hr = int(self.width_lr * self.upscaling_factor)\n",
    "\n",
    "        self.channels = channels\n",
    "        self.shape_lr = (self.height_lr, self.width_lr, self.channels)\n",
    "        self.shape_hr = (self.height_hr, self.width_hr, self.channels)\n",
    "\n",
    "        self.gen_lr = gen_lr\n",
    "        self.dis_lr = dis_lr\n",
    "        self.loss_weights = loss_weights\n",
    "        self.gan_loss = 'mse'\n",
    "        self.dis_loss = 'binary_crossentropy'\n",
    "\n",
    "        self.generator = self.build_generator()\n",
    "        self.compile_generator(self.generator)\n",
    "        #self.generator.summary()\n",
    "        if training_mode:\n",
    "            self.vgg = self.build_vgg()\n",
    "            self.compile_vgg(self.vgg)\n",
    "            self.discriminator = self.build_discriminator()\n",
    "            self.compile_discriminator(self.discriminator)\n",
    "            self.srgan = self.build_srgan()\n",
    "            self.compile_srgan(self.srgan)\n",
    "\n",
    "    def build_vgg(self):\n",
    "        img = Input(shape=self.shape_hr)\n",
    "        print(img.shape)\n",
    "        vgg = VGG19(weights=\"imagenet\")\n",
    "        vgg.outputs = [vgg.layers[20].output]\n",
    "        model = Model(inputs=img, outputs=vgg(img))\n",
    "        model.trainable = False\n",
    "        return model\n",
    "\n",
    "    def preprocess_vgg(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            return preprocess_input((x+1)*127.5)\n",
    "        else:            \n",
    "            return Lambda(lambda x: preprocess_input(tf.add(x, 1) * 127.5))(x)\n",
    "\n",
    "    def SubpixelConv2D(self, name, scale=2):\n",
    "\n",
    "        def subpixel_shape(input_shape):\n",
    "            dims = [input_shape[0],\n",
    "                    None if input_shape[1] is None else input_shape[1] * scale,\n",
    "                    None if input_shape[2] is None else input_shape[2] * scale,\n",
    "                    int(input_shape[3] / (scale ** 2))]\n",
    "            output_shape = tuple(dims)\n",
    "            return output_shape\n",
    "\n",
    "        def subpixel(x):\n",
    "            return tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "        return Lambda(subpixel, output_shape=subpixel_shape, name=name)\n",
    "\n",
    "    def build_generator(self, residual_blocks=16):\n",
    "\n",
    "        def residual_block(input):\n",
    "            x = Conv2D(64, kernel_size=3, strides=1, padding='same')(input)\n",
    "            x = BatchNormalization(momentum=0.8)(x)\n",
    "            x = PReLU(shared_axes=[1,2])(x)\n",
    "            x = Conv2D(64, kernel_size=3, strides=1, padding='same')(x)\n",
    "            x = Add()([x, input])\n",
    "            return x\n",
    "\n",
    "        def upsample(x, number):\n",
    "            x = Conv2D(256, kernel_size=3, strides=1, padding='same', name='upSampleConv2D_'+str(number))(x)\n",
    "            x = self.SubpixelConv2D('upSampleSubPixel_'+str(number), 2)(x)\n",
    "            x = PReLU(shared_axes=[1,2], name='upSamplePReLU_'+str(number))(x)\n",
    "            return x\n",
    "\n",
    "        lr_input = Input(shape=(None, None, 3))\n",
    "        x_start = Conv2D(64, kernel_size=9, strides=1, padding='same')(lr_input)\n",
    "        x_start = PReLU(shared_axes=[1,2])(x_start)\n",
    "\n",
    "        r = residual_block(x_start)\n",
    "        for _ in range(residual_blocks - 1):\n",
    "            r = residual_block(r)\n",
    "        \n",
    "        x = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = Add()([x, x_start])\n",
    "\n",
    "        x = upsample(x, 1)\n",
    "        if self.upscaling_factor > 2:\n",
    "            x = upsample(x, 2)\n",
    "        if self.upscaling_factor > 4:\n",
    "            x = upsample(x, 3)\n",
    "        \n",
    "        hr_output = Conv2D(\n",
    "            self.channels, \n",
    "            kernel_size=9, \n",
    "            strides=1, \n",
    "            padding='same', \n",
    "            activation='tanh'\n",
    "        )(x)\n",
    "\n",
    "        model = Model(inputs=lr_input, outputs=hr_output)        \n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self, filters=64):\n",
    "\n",
    "        def conv2d_block(input, filters, strides=1, bn=True):\n",
    "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img = Input(shape=self.shape_hr)\n",
    "        x = conv2d_block(img, filters, bn=False)\n",
    "        x = conv2d_block(x, filters, strides=2)\n",
    "        x = conv2d_block(x, filters*2)\n",
    "        x = conv2d_block(x, filters*2, strides=2)\n",
    "        x = conv2d_block(x, filters*4)\n",
    "        x = conv2d_block(x, filters*4, strides=2)\n",
    "        x = conv2d_block(x, filters*8)\n",
    "        x = conv2d_block(x, filters*8, strides=2)\n",
    "        x = Dense(filters*16)(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(inputs=img, outputs=x)\n",
    "        return model\n",
    "\n",
    "    def build_srgan(self):\n",
    "\n",
    "        img_lr = Input(self.shape_lr)\n",
    "        generated_hr = self.generator(img_lr)\n",
    "        generated_features = self.vgg(\n",
    "            self.preprocess_vgg(generated_hr)\n",
    "        )\n",
    "        self.discriminator.trainable = False\n",
    "        generated_check = self.discriminator(generated_hr)\n",
    "        generated_features = Lambda(lambda x: x, name='Content')(generated_features)\n",
    "        generated_check = Lambda(lambda x: x, name='Adversarial')(generated_check)\n",
    "\n",
    "        model = Model(inputs=img_lr, outputs=[generated_check, generated_features])        \n",
    "        return model\n",
    "\n",
    "    def PSNR(self, y_true, y_pred):\n",
    "        return -10.0 * K.log(K.mean(K.square(y_pred - y_true))) / K.log(10.0) \n",
    "\n",
    "    def compile_vgg(self, model):\n",
    "        model.compile(\n",
    "            loss='mse',\n",
    "            optimizer=Adam(0.0001, 0.9),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def compile_generator(self, model):\n",
    "        model.compile(\n",
    "            loss=self.gan_loss,\n",
    "            optimizer=Adam(self.gen_lr, 0.9),\n",
    "            metrics=['mse', self.PSNR]\n",
    "        )\n",
    "\n",
    "    def compile_discriminator(self, model):\n",
    "        model.compile(\n",
    "            loss=self.dis_loss,\n",
    "            optimizer=Adam(self.dis_lr, 0.9),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def compile_srgan(self, model):\n",
    "        model.compile(\n",
    "            loss=[self.dis_loss, self.gan_loss],\n",
    "            loss_weights=self.loss_weights,\n",
    "            optimizer=Adam(self.gen_lr, 0.9)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(None, 224, 224, 3)\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n574717952/574710816 [==============================] - 263s 0us/step\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fb5fcec058b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-14fda2003d08>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, height_lr, width_lr, channels, upscaling_factor, gen_lr, dis_lr, loss_weights, training_mode)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#self.generator.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-14fda2003d08>\u001b[0m in \u001b[0;36mbuild_vgg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mvgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    921\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       \u001b[0;32massert\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Could not compute output '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0moutput_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m       \u001b[0moutput_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    " gan = SRGAN(gen_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}